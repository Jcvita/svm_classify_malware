import numpy as np
import os
DATASET_DIR = 'dataset'

class SVM:
    @classmethod
    def create_hyperplane(w, b):
        hyperplane = []
        return hyperplane
    
    def __init__(self, hyperplane):
        self.hyperplane = hyperplane
    
    def fit(self, X, y):
        pass
    
    

def load_samples(labels, feats_dir):
    """load labled samples and identify unique features

    Args:
        labels (str): file containing labels
        feats_dir (str): directory containing feature files

    Returns:
        tuple: ( [([(type of feature, feature)], <mal or benign>, <mal family || None>)], { feat: type }, { family: occurrences } )
    """
    print("loading samples...")
    #todo can be optimized by sequential read and parse
    malware_samples = {x[0]: x[1] for x in list(map(lambda y: y.split(","), open(f'{labels}', 'r').readlines()[1:]))} # {sha256 filename: family)
    data = [] # [([(type of feature, feature)], <mal or benign>, <mal family || None>)]
    feats = {} # { <feat>: {type: str, vec_pos: int} }
    families = {} # { <family>: occurrences }
    count = 0
    feat_count = 0
    for hash, family in malware_samples.items():
        #insert into family dictionary
        if families.get(family) is None:
            families[family] = 0
        families[family] += 1
        
    #open sample and insert into data
    all_samples = os.listdir(feats_dir)
    num_samples = len(all_samples) - 1
    os.chdir(feats_dir)
    for hash in all_samples:
        with open(hash, 'r') as sample:
            lines = sample.readlines() # features of the sample
            # data.append(list(map(lambda x: tuple(x.split("::")), sample)))
            sample.close()

            features = []
            for line in lines:
                feat = line.split("::")
                # for some reason a ["/n"] feature appears likely at the end
                if len(feat) == 1:
                    continue
                # save sample features to data
                features.append(tuple(feat))
                # add feature to dictionary
                if feats.get(feat[1]) is None:
                    feats[feat[1]] = {"type": feat[0], "vec_pos": feat_count}
                    feat_count += 1
            data.append((features, 1 if malware_samples.get(hash) else 0, malware_samples.get(hash)))
        if count % (num_samples // 100) == 0:
            print(f'Samples {(count / num_samples) * 100}% loaded ')
        count += 1 
    
    print("Loading complete!")
    return data, feats#, families

def vectorize(family_file):
    os.chdir(DATASET_DIR)
    # Build a list of all unique feature strings present in the dataset.
    data, feats = load_samples(family_file, 'feature_vectors')
    
    unique = feats.keys()
    
    print("Vectorizing data")
    # For each sample, build a vector of 1s and 0s in which a 1 signals that the feature
    # was present in the sample and a 0 signals that it was not.
    feature_vectors = []
    for sample in data:
        feature_vector = [0]*len(unique)
        for type, feat in sample:
            feature_vector[feats[feat]["vec_pos"]] = 1
        feature_vectors.append(feature_vector)
    print("Finished Vectorizing data")
    return feature_vectors

def main():
    # 1. Dataset processing
    feature_vectors = vectorize('sha256_family.csv')
    print(len(feature_vectors[0]))
    # 2. SVM
if __name__ == '__main__':
    main()